{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation with attention\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int):\n",
    "            return self.E[:,x].reshape(self.embed_sz, 1)\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "        self.first_h_shape = None # debugging\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"If fixed, reuse same mask for all future uses of this layer.\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        if self.fixed:\n",
    "            if self.mask is None:\n",
    "                usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "                self.mask = (usample>self.p).int()           # get mask as those with value greater than p\n",
    "            mask = self.mask\n",
    "        else:\n",
    "            usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "            mask = (usample>self.p).int()                # get mask as those with value greater than p\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)\n",
    "        if isinstance(y, list):\n",
    "            y = torch.tensor(y)\n",
    "            \n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        assert y.dim()==1 or y.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "        if y.dim()==1:\n",
    "            y = y.reshape(1,-1)\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(y.shape[1]-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[:,t])\n",
    "            embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "            o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            y_true = torch.tensor(y[:,t+1], device=device).reshape(batch_size)\n",
    "            loss += F.cross_entropy(o, y_true, reduction=\"sum\")\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1)#.item()\n",
    "            correct += torch.sum(y_pred==y[:,t+1])\n",
    "            output.append(y_pred)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, Y_ctoi):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)\n",
    "\n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        loss = 0.0\n",
    "        output = []\n",
    "        y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "        output.append(y_pred)\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        MAX = 20 # for safety\n",
    "        while y_pred!=Y_ctoi['>'] and len(output)<=MAX:\n",
    "            embedding_step_t = self.emby(y_pred)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1).item()\n",
    "            output.append(y_pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:1000] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(f\"<{p[0]}>\",f\"<{p[1]}>\") for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<va>', '<go>'),\n",
       " ('<cours>', '<run>'),\n",
       " ('<courez>', '<run>'),\n",
       " ('<ça alors>', '<wow>'),\n",
       " ('<au feu>', '<fire>')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for p in pairs:\n",
    "    fr, en = p\n",
    "    X.append([ctoi[c] for c in fr])\n",
    "    Y.append([ctoi[c] for c in en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 41, 20, 1],\n",
       " [0, 22, 34, 40, 37, 38, 1],\n",
       " [0, 22, 34, 40, 37, 24, 45, 1],\n",
       " [0, 48, 20, 2, 20, 31, 34, 37, 38, 1],\n",
       " [0, 20, 40, 2, 25, 24, 40, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 26, 34, 1],\n",
       " [0, 37, 40, 33, 1],\n",
       " [0, 37, 40, 33, 1],\n",
       " [0, 42, 34, 42, 1],\n",
       " [0, 25, 28, 37, 24, 1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 training records, 10 embedding size, 64 target classes, state is 300-vector\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "char_embed_sz = 10\n",
    "nhidden = 300\n",
    "nclasses = len(vocab) # char output vocab\n",
    "\n",
    "print(f\"{n:,d} training records, {char_embed_sz} embedding size, {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    return ''.join([vocab[v] for v in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss   18.158   accur  0.0206   LR 0.000010\n",
      "Epoch   2 training loss    6.231   accur  0.2444   LR 0.000258\n",
      "Epoch   3 training loss    2.967   accur  0.4183   LR 0.000505\n",
      "Epoch   4 training loss    2.191   accur  0.5069   LR 0.000753\n",
      "Epoch   5 training loss    1.771   accur  0.5747   LR 0.001000\n",
      "Epoch   6 training loss    1.034   accur  0.7097   LR 0.000753\n",
      "Epoch   7 training loss    0.557   accur  0.8271   LR 0.000505\n",
      "Epoch   8 training loss    0.293   accur  0.9141   LR 0.000258\n",
      "Epoch   9 training loss    0.184   accur  0.9577   LR 0.000010\n",
      "Epoch  10 training loss    0.191   accur  0.9526   LR 0.000134\n",
      "Epoch  11 training loss    0.204   accur  0.9481   LR 0.000258\n",
      "Epoch  12 training loss    0.280   accur  0.9169   LR 0.000381\n",
      "Epoch  13 training loss    0.379   accur  0.8850   LR 0.000505\n",
      "Epoch  14 training loss    0.192   accur  0.9417   LR 0.000381\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5c2daeaee8ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# autograd computes U.grad, M.grad, ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=0.0,\n",
    "                   useGRU=True)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=4,\n",
    "#                                               base_lr=0.000001, max_lr=0.0005,\n",
    "                                              base_lr=0.00001, max_lr=0.001,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 20\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total_compares = 0\n",
    "    for i in torch.randperm(n):\n",
    "#     for i in range(n):\n",
    "        x = X_train[i]\n",
    "        y = Y_train[i]\n",
    "        y_pred, loss, correct = trans(x, y)\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += len(y) - 1  # From \"<foo>\" predict and count \"foo>\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_training_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:8.3f}   accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def same(a,b):\n",
    "#     return sum(c1==c2 for c1,c2 in zip(a,b))\n",
    "\n",
    "def check(X,Y,verbose=False):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        valid_accur = 0\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = trans.predict(x, ctoi)\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose:\n",
    "                print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d, total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training average Levenshtein score     0.97, perfect accuracy     0.81\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_train, Y_train)\n",
    "print(f\"Training average Levenshtein score {total_d/len(X_train):8.2f}, perfect accuracy {total_correct/len(X_train):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sois détendu>       : <be cool>\n",
      "                     : <it's lost>          Levenshtein 7 out of 9\n",
      "<tenez ça>           : <hold this>\n",
      "                     : <stop that>          Levenshtein 6 out of 11\n",
      "<je vous ai vue>     : <i saw you>\n",
      "                     : <i saw you>          Levenshtein 0 out of 11\n",
      "<ça fonctionnera>    : <it'll work>\n",
      "                     : <it's work>          Levenshtein 2 out of 12\n",
      "<j'étais malade>     : <i was sick>\n",
      "                     : <i am sick>          Levenshtein 2 out of 12\n",
      "<je suis loyale>     : <i'm loyal>\n",
      "                     : <i funss>            Levenshtein 7 out of 11\n",
      "<pardonnez-moi>      : <forgive me>\n",
      "                     : <leave up>           Levenshtein 7 out of 12\n",
      "<je chanterai>       : <i'll sing>\n",
      "                     : <i'll wos>           Levenshtein 4 out of 11\n",
      "<vous, décidez>      : <you decide>\n",
      "                     : <you drive>          Levenshtein 3 out of 12\n",
      "<je l'ai fait>       : <i did it>\n",
      "                     : <i stardd it>        Levenshtein 5 out of 10\n",
      "<oh vraiment >       : <oh, really>\n",
      "                     : <who slweft>         Levenshtein 8 out of 12\n",
      "<tom ronfle>         : <tom snores>\n",
      "                     : <tak tom sorry>      Levenshtein 7 out of 12\n",
      "<tiens ceci>         : <hold this>\n",
      "                     : <here it up>         Levenshtein 7 out of 11\n",
      "<sens ça>            : <feel this>\n",
      "                     : <feel this>          Levenshtein 0 out of 11\n",
      "<je suis désolé>     : <i am sorry>\n",
      "                     : <i am sorry>         Levenshtein 0 out of 12\n",
      "<j'utilise cela>     : <i use this>\n",
      "                     : <i did that>         Levenshtein 5 out of 12\n",
      "<allez au lit>       : <get to bed>\n",
      "                     : <get to bed>         Levenshtein 0 out of 12\n",
      "<il fait nuit>       : <it's night>\n",
      "                     : <is it son>          Levenshtein 8 out of 12\n",
      "<je suis loyal>      : <i'm loyal>\n",
      "                     : <i'm strice>         Levenshtein 6 out of 11\n",
      "<j'en doute>         : <i doubt it>\n",
      "                     : <i like you>         Levenshtein 8 out of 12\n",
      "<je vais bien>       : <i am okay>\n",
      "                     : <i'm fine>           Levenshtein 6 out of 11\n",
      "<je suis flasque>    : <i'm flabby>\n",
      "                     : <i'm bust>           Levenshtein 6 out of 12\n",
      "<soyez justes>       : <be fair>\n",
      "                     : <be careful>         Levenshtein 6 out of 9\n",
      "<il a à faire>       : <he is busy>\n",
      "                     : <let it be>          Levenshtein 6 out of 12\n",
      "<vraiment >          : <no kidding>\n",
      "                     : <who slweft>         Levenshtein 9 out of 12\n",
      "<je les ai vues>     : <i saw them>\n",
      "                     : <i saw you>          Levenshtein 4 out of 12\n",
      "<il est fauché>      : <he's broke>\n",
      "                     : <i'm broke>          Levenshtein 3 out of 12\n",
      "<je suis honnête>    : <i'm honest>\n",
      "                     : <i'm ready>          Levenshtein 6 out of 12\n",
      "<attrape ça>         : <grab this>\n",
      "                     : <stop that>          Levenshtein 6 out of 11\n",
      "<ça alors>           : <wow>\n",
      "                     : <go>                 Levenshtein 2 out of 5\n",
      "<ai-je gagné >       : <did i win>\n",
      "                     : <is he won>          Levenshtein 5 out of 11\n",
      "<je suis crevé>      : <i'm pooped>\n",
      "                     : <i'm broke it>       Levenshtein 6 out of 12\n",
      "<viens>              : <come over>\n",
      "                     : <come back>          Levenshtein 4 out of 11\n",
      "<j'étais occupée>    : <i was busy>\n",
      "                     : <i'm busy>           Levenshtein 4 out of 12\n",
      "<tom est venu>       : <tom came>\n",
      "                     : <it's alt>           Levenshtein 6 out of 10\n",
      "<je le vis>          : <i saw him>\n",
      "                     : <i saw you>          Levenshtein 3 out of 11\n",
      "<soyez satisfait>    : <be content>\n",
      "                     : <be content>         Levenshtein 0 out of 12\n",
      "<viens chez moi>     : <come over>\n",
      "                     : <come to me>         Levenshtein 4 out of 11\n",
      "<il est malade>      : <he is sick>\n",
      "                     : <i was sick>         Levenshtein 4 out of 12\n",
      "<sérieusement >      : <seriously>\n",
      "                     : <who slewa>          Levenshtein 8 out of 11\n",
      "<essayez-en>         : <try some>\n",
      "                     : <get tomu's saw him> Levenshtein 15 out of 10\n",
      "<prenez ça>          : <take this>\n",
      "                     : <stop that>          Levenshtein 6 out of 11\n",
      "<moi aussi>          : <me, too>\n",
      "                     : <he is me>           Levenshtein 7 out of 9\n",
      "<j'ai pigé>          : <got it>\n",
      "                     : <i'm woned>          Levenshtein 8 out of 8\n",
      "<retirez-vous>       : <back off>\n",
      "                     : <step aside>         Levenshtein 9 out of 10\n",
      "<c'est pour moi>     : <it's on me>\n",
      "                     : <tome to me>         Levenshtein 6 out of 12\n",
      "<tom tricote>        : <tom knits>\n",
      "                     : <topiún>             Levenshtein 6 out of 11\n",
      "<c'est important>    : <it matters>\n",
      "                     : <it's fun>           Levenshtein 8 out of 12\n",
      "<ne bouge pas>       : <don't move>\n",
      "                     : <don't fret>         Levenshtein 4 out of 12\n",
      "<essaies-en>         : <try some>\n",
      "                     : <take it>            Levenshtein 7 out of 10\n",
      "<je suis reposé>     : <i'm rested>\n",
      "                     : <i'm broke it>       Levenshtein 7 out of 12\n",
      "<je suis connue>     : <i'm famous>\n",
      "                     : <i'm famous>         Levenshtein 0 out of 12\n",
      "<c'est propre>       : <it's clean>\n",
      "                     : <it ast ast>         Levenshtein 8 out of 12\n",
      "<j'ai oublié>        : <i forgot>\n",
      "                     : <i'm yout>           Levenshtein 6 out of 10\n",
      "<bonne chance>       : <good luck>\n",
      "                     : <stay this>          Levenshtein 8 out of 11\n",
      "<nous t'avons vu>    : <we saw you>\n",
      "                     : <we saw it>          Levenshtein 3 out of 12\n",
      "<compris>            : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 8\n",
      "<répondez-moi>       : <answer me>\n",
      "                     : <leave up>           Levenshtein 7 out of 11\n",
      "<montrez-moi>        : <show me>\n",
      "                     : <show me>            Levenshtein 0 out of 9\n",
      "<ce n'est rien>      : <no problem>\n",
      "                     : <it's swet>          Levenshtein 9 out of 12\n",
      "<je vous ai vu>      : <i saw you>\n",
      "                     : <i saw him>          Levenshtein 3 out of 11\n",
      "<je suis gras>       : <i am fat>\n",
      "                     : <i'm drunk>          Levenshtein 7 out of 10\n",
      "<suis-je grosse >    : <am i fat>\n",
      "                     : <am i rong>          Levenshtein 4 out of 10\n",
      "<j'entrerai>         : <i'll go in>\n",
      "                     : <i'll work>          Levenshtein 4 out of 12\n",
      "<je les ai vus>      : <i saw them>\n",
      "                     : <i saw you>          Levenshtein 4 out of 12\n",
      "<restez calme>       : <stay calm>\n",
      "                     : <stay calm>          Levenshtein 0 out of 11\n",
      "<j'aime ça>          : <i like it>\n",
      "                     : <i liked it>         Levenshtein 1 out of 11\n",
      "<reste calme>        : <stay calm>\n",
      "                     : <stay calm>          Levenshtein 0 out of 11\n",
      "<ne courez pas>      : <don't run>\n",
      "                     : <don't run>          Levenshtein 0 out of 11\n",
      "<viens chez nous>    : <come over>\n",
      "                     : <come us>            Levenshtein 4 out of 11\n",
      "<sois équitable>     : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 9\n",
      "<abandonne>          : <give it up>\n",
      "                     : <i give up>          Levenshtein 5 out of 12\n",
      "<c'est du sable>     : <it's sand>\n",
      "                     : <i'm lost>           Levenshtein 6 out of 11\n",
      "<sois prudente>      : <be careful>\n",
      "                     : <be careful>         Levenshtein 0 out of 12\n",
      "<venez>              : <come over>\n",
      "                     : <come back>          Levenshtein 4 out of 11\n",
      "<il raccrocha>       : <he hung up>\n",
      "                     : <he it up>           Levenshtein 4 out of 12\n",
      "<il est riche>       : <he's rich>\n",
      "                     : <tom cheats>         Levenshtein 10 out of 11\n",
      "<elle a souri>       : <she smiled>\n",
      "                     : <i'm cours>          Levenshtein 9 out of 12\n",
      "<oublie>             : <forget it>\n",
      "                     : <hurry up>           Levenshtein 7 out of 11\n",
      "<qui a parlé >       : <who talked>\n",
      "                     : <how helped>         Levenshtein 5 out of 12\n",
      "<n'entrez pas>       : <keep out>\n",
      "                     : <don't talk>         Levenshtein 9 out of 10\n",
      "<je suis revenu>     : <i'm back>\n",
      "                     : <i'm lost>           Levenshtein 4 out of 10\n",
      "<parle-moi>          : <talk to me>\n",
      "                     : <leave me>           Levenshtein 6 out of 12\n",
      "<à votre santé>      : <cheers>\n",
      "                     : <it sot>             Levenshtein 6 out of 8\n",
      "<je suis prêt>       : <i am ready>\n",
      "                     : <i'm lusly>          Levenshtein 6 out of 12\n",
      "<qui sait >          : <who knows>\n",
      "                     : <who did it>         Levenshtein 6 out of 11\n",
      "<qui est malade >    : <who's ill>\n",
      "                     : <who sis it>         Levenshtein 5 out of 11\n",
      "<tiens bon>          : <hang on>\n",
      "                     : <he's good>          Levenshtein 6 out of 9\n",
      "<avance>             : <drive on>\n",
      "                     : <i'm drined>         Levenshtein 8 out of 10\n",
      "<appelle tom>        : <call tom>\n",
      "                     : <sh upryom>          Levenshtein 7 out of 10\n",
      "<nous avons fini>    : <we're done>\n",
      "                     : <come one>           Levenshtein 5 out of 12\n",
      "<j'en ai vu une>     : <i saw one>\n",
      "                     : <i want one>         Levenshtein 3 out of 11\n",
      "<aide-nous>          : <help us>\n",
      "                     : <help us>            Levenshtein 0 out of 9\n",
      "<tom a regardé>      : <tom looked>\n",
      "                     : <i'm lobey>          Levenshtein 5 out of 12\n",
      "<tom a oublié>       : <tom forgot>\n",
      "                     : <he it sied>         Levenshtein 10 out of 12\n",
      "<est-ce toi >        : <is it you>\n",
      "                     : <am i stop>          Levenshtein 6 out of 11\n",
      "<reste baissé>       : <stay down>\n",
      "                     : <stay down>          Levenshtein 0 out of 11\n",
      "<je suis libre>      : <i'm free>\n",
      "                     : <i'm going>          Levenshtein 5 out of 10\n",
      "<reste debout>       : <stay awake>\n",
      "                     : <that's all>         Levenshtein 8 out of 12\n",
      "<oubliez-le>         : <forget him>\n",
      "                     : <forget him>         Levenshtein 0 out of 12\n",
      "<filez>              : <run for it>\n",
      "                     : <come over>          Levenshtein 9 out of 12\n",
      "<je cuis>            : <i'm baking>\n",
      "                     : <i saw you>          Levenshtein 8 out of 12\n",
      "<c'est parti>        : <here we go>\n",
      "                     : <tom's left>         Levenshtein 9 out of 12\n",
      "<attends ici>        : <wait here>\n",
      "                     : <we're here>         Levenshtein 4 out of 11\n",
      "<je suis fatigué>    : <i'm sleepy>\n",
      "                     : <i'm busy>           Levenshtein 5 out of 12\n",
      "<ça y est>           : <this is it>\n",
      "                     : <get there>          Levenshtein 9 out of 12\n",
      "<je suis saoul>      : <i'm loaded>\n",
      "                     : <i'm cod>            Levenshtein 4 out of 12\n",
      "<prends le mien>     : <take mine>\n",
      "                     : <i'm yours>          Levenshtein 9 out of 11\n",
      "<tom bailla>         : <tom yawned>\n",
      "                     : <tom sicghmt>        Levenshtein 7 out of 12\n",
      "<magnifique>         : <wonderful>\n",
      "                     : <fantsic>            Levenshtein 8 out of 11\n",
      "<je suis occupé>     : <i am busy>\n",
      "                     : <i'm busy>           Levenshtein 2 out of 11\n",
      "<je le refuse>       : <i refuse>\n",
      "                     : <i refuse>           Levenshtein 0 out of 10\n",
      "<je fus bonne>       : <i was good>\n",
      "                     : <i was good>         Levenshtein 0 out of 12\n",
      "<aidez-moi>          : <help me>\n",
      "                     : <call me>            Levenshtein 3 out of 9\n",
      "<bien joué>          : <good job>\n",
      "                     : <i'm shaken>         Levenshtein 10 out of 10\n",
      "<sauvez-vous>        : <run for it>\n",
      "                     : <step aside>         Levenshtein 10 out of 12\n",
      "<regarde-nous>       : <watch us>\n",
      "                     : <leave us>           Levenshtein 5 out of 10\n",
      "<maman a pleuré>     : <mama cried>\n",
      "                     : <i'm sticed>         Levenshtein 6 out of 12\n",
      "<il court>           : <he runs>\n",
      "                     : <she ruse surse>     Levenshtein 8 out of 9\n",
      "<laissez tomber>     : <leave it>\n",
      "                     : <give it up>         Levenshtein 6 out of 10\n",
      "<je suis coincée>    : <i'm stuck>\n",
      "                     : <i'm ruined>         Levenshtein 6 out of 11\n",
      "<j'ai perdu>         : <i've lost>\n",
      "                     : <i was lost>         Levenshtein 4 out of 11\n",
      "<je vous ai vues>    : <i saw you>\n",
      "                     : <i saw you>          Levenshtein 0 out of 11\n",
      "<allez-vous en>      : <go away>\n",
      "                     : <choose on>          Levenshtein 8 out of 9\n",
      "<j'adorais ça>       : <i loved it>\n",
      "                     : <i liked it>         Levenshtein 2 out of 12\n",
      "<sois juste>         : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 9\n",
      "<il est soûl>        : <he's drunk>\n",
      "                     : <it's saw me>        Levenshtein 8 out of 12\n",
      "<préparez-vous>      : <get ready>\n",
      "                     : <step aside>         Levenshtein 7 out of 11\n",
      "<signe ici>          : <sign here>\n",
      "                     : <is it sicwe>        Levenshtein 8 out of 11\n",
      "<je suis resté>      : <i stayed>\n",
      "                     : <i'm broke it>       Levenshtein 9 out of 10\n",
      "<nous discutâmes>    : <we talked>\n",
      "                     : <we lost>            Levenshtein 5 out of 11\n",
      "<arrête>             : <cut it out>\n",
      "                     : <stopúnúún>          Levenshtein 9 out of 12\n",
      "<je dois courir>     : <i must run>\n",
      "                     : <i'm cough>          Levenshtein 8 out of 12\n",
      "<pas touche>         : <hands off>\n",
      "                     : <turn left>          Levenshtein 8 out of 11\n",
      "<épouse-moi>         : <marry me>\n",
      "                     : <follow me>          Levenshtein 6 out of 10\n",
      "<soyez sérieux>      : <be serious>\n",
      "                     : <i mean it>          Levenshtein 8 out of 12\n",
      "<je te veux>         : <i want you>\n",
      "                     : <i want it>          Levenshtein 3 out of 12\n",
      "<soyez gentilles>    : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 9\n",
      "<je les vis>         : <i saw them>\n",
      "                     : <i saw you>          Levenshtein 4 out of 12\n",
      "<j'ai crié>          : <i screamed>\n",
      "                     : <i'm brot>           Levenshtein 9 out of 12\n",
      "<je sais courir>     : <i can run>\n",
      "                     : <i'm cough>          Levenshtein 8 out of 11\n",
      "<attendez ici>       : <wait here>\n",
      "                     : <come to here>       Levenshtein 6 out of 11\n",
      "<il est pauvre>      : <he is poor>\n",
      "                     : <it's yours>         Levenshtein 7 out of 12\n",
      "<stop>               : <stop>\n",
      "                     : <gorght>             Levenshtein 6 out of 6\n",
      "<sois sérieux>       : <be serious>\n",
      "                     : <she it mank>        Levenshtein 9 out of 12\n",
      "<je vous envie>      : <i envy you>\n",
      "                     : <i envy him>         Levenshtein 3 out of 12\n",
      "<c'est prêt>         : <it's ready>\n",
      "                     : <it's lopsg>         Levenshtein 5 out of 12\n",
      "<je sais nager>      : <i can swim>\n",
      "                     : <i'm fung suei>      Levenshtein 8 out of 12\n",
      "<j'ai vu cela>       : <i saw that>\n",
      "                     : <i did that>         Levenshtein 3 out of 12\n",
      "<augmente-le>        : <turn it up>\n",
      "                     : <turn it up>         Levenshtein 0 out of 12\n",
      "<elle est venue>     : <she came>\n",
      "                     : <i'm baly>           Levenshtein 6 out of 10\n",
      "<je suis cupide>     : <i'm greedy>\n",
      "                     : <i'm timid>          Levenshtein 5 out of 12\n",
      "<lis ceci>           : <read this>\n",
      "                     : <use this>           Levenshtein 4 out of 11\n",
      "<désolé>             : <i'm sorry>\n",
      "                     : <stay away>          Levenshtein 8 out of 11\n",
      "<embrassez-moi>      : <kiss me>\n",
      "                     : <leave me>           Levenshtein 5 out of 9\n",
      "<excellent>          : <terrific>\n",
      "                     : <they swam>          Levenshtein 7 out of 10\n",
      "<est-ce vous >       : <is it you>\n",
      "                     : <who sis>            Levenshtein 8 out of 11\n",
      "<je sais lire>       : <i can read>\n",
      "                     : <i'm going>          Levenshtein 9 out of 12\n",
      "<prépare-toi>        : <get ready>\n",
      "                     : <step aside>         Levenshtein 7 out of 11\n",
      "<je suis alitée>     : <i'm in bed>\n",
      "                     : <i'm in himed>       Levenshtein 3 out of 12\n",
      "<on est partis>      : <here we go>\n",
      "                     : <tom's left>         Levenshtein 9 out of 12\n",
      "<il est ruiné>       : <he's broke>\n",
      "                     : <i'm ruined>         Levenshtein 8 out of 12\n",
      "<ça suffit>          : <stop>\n",
      "                     : <be contenr>         Levenshtein 9 out of 6\n",
      "<menottez-le>        : <cuff him>\n",
      "                     : <turn it up>         Levenshtein 8 out of 10\n",
      "<nous nagerons>      : <we'll swim>\n",
      "                     : <we'll win>          Levenshtein 2 out of 12\n",
      "<j'ai téléphoné>     : <i phoned>\n",
      "                     : <it worked>          Levenshtein 5 out of 10\n",
      "<signez ici>         : <sign here>\n",
      "                     : <come over>          Levenshtein 7 out of 11\n",
      "<je suis normale>    : <i'm normal>\n",
      "                     : <i'm norme>          Levenshtein 2 out of 12\n",
      "<va t'échauffer>     : <go warm up>\n",
      "                     : <i can walk>         Levenshtein 9 out of 12\n",
      "<il est ivre>        : <he's drunk>\n",
      "                     : <it's yours>         Levenshtein 6 out of 12\n",
      "<reste malin>        : <stay sharp>\n",
      "                     : <fill it up>         Levenshtein 8 out of 12\n",
      "<soyez prudent>      : <be careful>\n",
      "                     : <be careful>         Levenshtein 0 out of 12\n",
      "<ils sont partis>    : <they left>\n",
      "                     : <tom's left>         Levenshtein 4 out of 11\n",
      "<ils nagèrent>       : <they swam>\n",
      "                     : <they swam>          Levenshtein 0 out of 11\n",
      "Testing average Levenshtein score     5.31, perfect accuracy     0.14\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_test, Y_test, verbose=True)\n",
    "print(f\"Testing average Levenshtein score {total_d/len(X_test):8.2f}, perfect accuracy {total_correct/len(X_test):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
