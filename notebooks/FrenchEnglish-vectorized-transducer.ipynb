{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation vectorized\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```\n",
    "\n",
    "With dropout, I get this to be about 25% accurate for exactly correct translations in 20% test set.  I consider that pretty good given the small dataset and that I'm using chars not words.  Even the imperfect ones are sometimes really close or even semantically same but lexically different. Dropout definitely seems to make a difference.  With 1000 training records, I can get to about 15% accuracy on the test set with dropout=0.5, 700 hidden, and 32 batch size. `Testing n=177 average Levenshtein score     5.76, perfect accuracy     0.14`  With 512 hidden, I can only get to about 10% accuracy on the test set.\n",
    "\n",
    "Dang!  I forgot to shuffle X,Y at each epoch.  I think this helps with the stochastic nature and might even allow a larger batch size to improve efficiency.  Hmmm... by shuffling, 700 hidden 32 batch size dropout 0.5, gives `Testing n=177 average Levenshtein score     5.76, perfect accuracy     0.13` about the same. ok, still right thing to do.  Oops. bug. was shuffling X,Y not X_train, ...\n",
    "\n",
    "RNN (vs GRU) gets `Testing n=177 average Levenshtein score     6.78, perfect accuracy     0.07` for same setup so not as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    ridx = torch.randperm(len(X))\n",
    "    X = X[ridx]\n",
    "    Y = Y[ridx]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int) or (x.dim()==0 or isinstance(x, torch.Tensor) and x.dim()==1 and len(x)==1):\n",
    "            batch_size = 1\n",
    "        elif isinstance(x, torch.Tensor) and x.dim()==1:\n",
    "            batch_size = x.shape[0]\n",
    "        if isinstance(x, torch.Tensor): x.dim()==1\n",
    "        \n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x].reshape(self.embed_sz, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"\"\"\n",
    "        If fixed, reuse same mask for all future uses of this layer.\n",
    "        Assumes v columns are the layer activations. If batch size is 1, then this will be a column vector.\n",
    "        Same column knockout used future invocations if fixed.\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        return v\n",
    "        \"\"\"\n",
    "        Column(s) are activation vectors. Get a new column mask and knockout elements with\n",
    "        it for each column (unless fixed).\n",
    "        \"\"\"\n",
    "        if isinstance(v, list):\n",
    "            v = torch.tensor(v, device=device)\n",
    "\n",
    "        if self.fixed and self.mask is None:\n",
    "            mast = self.mask = (usample>self.p).int()\n",
    "\n",
    "        usample = torch.empty_like(v).uniform_(0, 1)     # get random value for each activation matrix element\n",
    "        mask = (usample>self.p).int()                    # get boolean mask as \"those with value greater than p\"\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 20.],\n",
       "        [ 1., 21.],\n",
       "        [ 2., 22.],\n",
       "        [ 3., 23.],\n",
       "        [ 4., 24.],\n",
       "        [ 5., 25.],\n",
       "        [ 6., 26.],\n",
       "        [ 7., 27.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([range(8),range(20,28)], dtype=torch.float64).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 21., 22., 23., 24., 25., 26., 27.], dtype=torch.float64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135614"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9748"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 18\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:500] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5],\n",
       "        [1, 6],\n",
       "        [2, 7],\n",
       "        [3, 8],\n",
       "        [4, 9]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(5)).reshape(-1,1)\n",
    "b = torch.tensor(range(5,10)).reshape(-1,1)\n",
    "torch.cat([a,b], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(f\"{p[0]}\",f\"<{p[1]}>\") for p in pairs]  # X doesn't need <...> brackets\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 46,  2, 31,  4, 20, 28, 23, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 20, 40, 39, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 48, 20,  2, 38, 40, 25, 25, 28, 39],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 39, 34, 35],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0, 20, 37, 37, 51, 39, 24,  7, 39, 34, 28]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize and left pad\n",
    "X = torch.zeros(len(pairs), MAX_LENGTH, device=device, dtype=torch.long) # zero implies padding\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(fr)\n",
    "    for j in range(len(fr)):\n",
    "        X[i,j+pad] = ctoi[fr[j]]\n",
    "X[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 26, 34,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 42, 34, 42,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 25, 28, 37, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(en) + 2 # include <...>\n",
    "    Y.append([ctoi[d] for d in en]+[ctoi['>']]*pad)  # pad with \"end of string\" symbols '>'\n",
    "Y = torch.tensor(Y, device=device)\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed_sz = 10\n",
    "nhidden = 512\n",
    "nclasses = len(vocab) # char output vocab\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X)\n",
    "n = batch_size * n//batch_size\n",
    "X, Y = X[:n], Y[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "# split\n",
    "ntrain = int(0.8 * len(X))\n",
    "X_train, X_test = X[:ntrain], X[ntrain:]\n",
    "Y_train, Y_test = Y[:ntrain], Y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    s = ''.join([vocab[v] for v in x])\n",
    "    if '>' in s:\n",
    "        i = s.index('>')\n",
    "        return s[0:i+1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        encoder_h_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        decoder_h_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x, device=device)\n",
    "        if isinstance(y, list):\n",
    "            y = torch.tensor(y, device=device)\n",
    "        \n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        assert y.dim()==1 or y.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "        if y.dim()==1:\n",
    "            y = y.reshape(1,-1)\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "            h = encoder_h_dropout(h)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(y.shape[1]-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[:,t])\n",
    "            embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            h = decoder_h_dropout(h)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "            o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            y_true = torch.tensor(y[:,t+1], device=device).reshape(batch_size)\n",
    "            loss += F.cross_entropy(o, y_true, reduction=\"sum\")\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1) # y_pred has prediction for each record in batch\n",
    "            correct += torch.sum(y_pred==y[:,t+1])\n",
    "            output.append(y_pred.reshape(-1,1))\n",
    "        output = torch.cat(output, dim=1) # should be batch_size by (columns(y)-1)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, y=None):\n",
    "        \"if y not none, compute loss, accuracy\"\n",
    "        with torch.no_grad():\n",
    "            if isinstance(x, list):\n",
    "                x = torch.tensor(x, device=device)\n",
    "\n",
    "            assert x.dim()==1 or x.dim()==2 \n",
    "\n",
    "            if x.dim()==1:\n",
    "                batch_size = 1\n",
    "                x = x.reshape(1,-1)\n",
    "            else:\n",
    "                batch_size = x.shape[0]\n",
    "\n",
    "            # ENCODER\n",
    "            h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "            for t in range(x.shape[1]):\n",
    "                embedding_step_t = self.embx(x[:,t])\n",
    "                h = self.encoder(h, embedding_step_t)\n",
    "            c = h\n",
    "\n",
    "            # DECODER\n",
    "            loss = 0.0\n",
    "            correct = 0\n",
    "            output = []\n",
    "            # y_pred is column vector starting with '<' for each record in the batch\n",
    "            y_pred = ctoi['<']\n",
    "            y_pred = torch.full(size=(batch_size,1), fill_value=y_pred, device=device, dtype=torch.long) # begin with \"start of sequence\" char\n",
    "            output.append(y_pred)\n",
    "            h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "            while len(output)<MAX_LENGTH+2: # max plus last '>' char\n",
    "                embedding_step_t = self.emby(y_pred.flatten())  # make it a list of symbols to use in embedding\n",
    "                h = self.decoder(h, c, embedding_step_t)\n",
    "                o = self.lin(h)\n",
    "                p = F.softmax(o, dim=1)\n",
    "                y_pred = torch.argmax(p, dim=1).reshape(-1,1)\n",
    "                output.append(y_pred)\n",
    "            output = torch.cat(output, dim=1) # should be batch_size by (columns(y)-1)\n",
    "        return output  \n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        \"Return raw accuracy of perfect translations to total records\"\n",
    "        with torch.no_grad():\n",
    "            y_pred = trans.predict(X_test)\n",
    "            correct = 0\n",
    "            for i in range(len(X_test)):\n",
    "                correct += tostr(y_pred[i])==tostr(Y_test[i])\n",
    "    #     y_pred_real_char = torch.sum(y_pred>1)\n",
    "    #     y_real_char = torch.sum(Y_test>1)\n",
    "    #     print(torch.sum(Y_test>1))\n",
    "    #     print(y_pred)\n",
    "    #     print(Y_test)\n",
    "    #     print(y_pred==Y_test)\n",
    "        return correct/float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 TRAIN loss 53.2427 char accur 0.0072 phrase accur 0.0000    TEST accur 0.000   LR 0.000050\n",
      "Epoch   2 TRAIN loss 20.7365 char accur 0.3630 phrase accur 0.0000    TEST accur 0.000   LR 0.000367\n",
      "Epoch   3 TRAIN loss  9.9511 char accur 0.5961 phrase accur 0.0000    TEST accur 0.000   LR 0.000683\n",
      "Epoch   4 TRAIN loss  6.2591 char accur 0.6540 phrase accur 0.0000    TEST accur 0.000   LR 0.001000\n",
      "Epoch   5 TRAIN loss  4.0876 char accur 0.7087 phrase accur 0.0029    TEST accur 0.000   LR 0.000683\n",
      "Epoch   6 TRAIN loss  2.9483 char accur 0.7409 phrase accur 0.0000    TEST accur 0.000   LR 0.000367\n",
      "Epoch   7 TRAIN loss  2.4738 char accur 0.7712 phrase accur 0.0115    TEST accur 0.000   LR 0.000050\n",
      "Epoch   8 TRAIN loss  2.3078 char accur 0.7792 phrase accur 0.0201    TEST accur 0.000   LR 0.000208\n",
      "Epoch   9 TRAIN loss  1.9842 char accur 0.7975 phrase accur 0.0201    TEST accur 0.000   LR 0.000367\n",
      "Epoch  10 TRAIN loss  1.6132 char accur 0.8189 phrase accur 0.0516    TEST accur 0.011   LR 0.000525\n",
      "Epoch  11 TRAIN loss  1.2527 char accur 0.8430 phrase accur 0.0860    TEST accur 0.011   LR 0.000367\n",
      "Epoch  12 TRAIN loss  1.0331 char accur 0.8660 phrase accur 0.1433    TEST accur 0.023   LR 0.000208\n",
      "Epoch  13 TRAIN loss  0.9194 char accur 0.8805 phrase accur 0.1633    TEST accur 0.023   LR 0.000050\n",
      "Epoch  14 TRAIN loss  0.8791 char accur 0.8861 phrase accur 0.1605    TEST accur 0.011   LR 0.000129\n",
      "Epoch  15 TRAIN loss  0.8129 char accur 0.8901 phrase accur 0.1891    TEST accur 0.034   LR 0.000208\n",
      "Epoch  16 TRAIN loss  0.7257 char accur 0.8959 phrase accur 0.2751    TEST accur 0.034   LR 0.000287\n",
      "Epoch  17 TRAIN loss  0.6197 char accur 0.9115 phrase accur 0.3152    TEST accur 0.045   LR 0.000208\n",
      "Epoch  18 TRAIN loss  0.5571 char accur 0.9193 phrase accur 0.3181    TEST accur 0.034   LR 0.000129\n",
      "Epoch  19 TRAIN loss  0.5171 char accur 0.9248 phrase accur 0.3266    TEST accur 0.034   LR 0.000050\n",
      "Epoch  20 TRAIN loss  0.5027 char accur 0.9264 phrase accur 0.3467    TEST accur 0.045   LR 0.000090\n",
      "Epoch  21 TRAIN loss  0.4794 char accur 0.9273 phrase accur 0.3553    TEST accur 0.034   LR 0.000129\n",
      "Epoch  22 TRAIN loss  0.4492 char accur 0.9303 phrase accur 0.3954    TEST accur 0.057   LR 0.000169\n",
      "Epoch  23 TRAIN loss  0.4090 char accur 0.9342 phrase accur 0.3954    TEST accur 0.057   LR 0.000129\n",
      "Epoch  24 TRAIN loss  0.3823 char accur 0.9379 phrase accur 0.4097    TEST accur 0.045   LR 0.000090\n",
      "Epoch  25 TRAIN loss  0.3631 char accur 0.9414 phrase accur 0.4126    TEST accur 0.080   LR 0.000050\n",
      "Epoch  26 TRAIN loss  0.3533 char accur 0.9412 phrase accur 0.4413    TEST accur 0.080   LR 0.000070\n",
      "Epoch  27 TRAIN loss  0.3414 char accur 0.9430 phrase accur 0.4384    TEST accur 0.080   LR 0.000090\n",
      "Epoch  28 TRAIN loss  0.3250 char accur 0.9429 phrase accur 0.4499    TEST accur 0.080   LR 0.000109\n",
      "Epoch  29 TRAIN loss  0.3075 char accur 0.9475 phrase accur 0.4441    TEST accur 0.068   LR 0.000090\n",
      "Epoch  30 TRAIN loss  0.2925 char accur 0.9492 phrase accur 0.4699    TEST accur 0.091   LR 0.000070\n",
      "Epoch  31 TRAIN loss  0.2809 char accur 0.9499 phrase accur 0.4699    TEST accur 0.080   LR 0.000050\n",
      "Epoch  32 TRAIN loss  0.2736 char accur 0.9501 phrase accur 0.4756    TEST accur 0.080   LR 0.000060\n",
      "Epoch  33 TRAIN loss  0.2658 char accur 0.9501 phrase accur 0.5043    TEST accur 0.080   LR 0.000070\n",
      "Epoch  34 TRAIN loss  0.2556 char accur 0.9510 phrase accur 0.5043    TEST accur 0.080   LR 0.000080\n",
      "Epoch  35 TRAIN loss  0.2456 char accur 0.9525 phrase accur 0.5014    TEST accur 0.091   LR 0.000070\n"
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=0.0,\n",
    "                   useGRU=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=3,\n",
    "                                              base_lr=0.00005, max_lr=0.001,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 35\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accum_accur = 0.0\n",
    "    total_compares = 0\n",
    "    X_train,Y_train = shuffle(X_train,Y_train)\n",
    "    for p in range(0, len(X_train), batch_size):  # do one epoch\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_Y = Y_train[p:p+batch_size]\n",
    "        y_pred, loss, correct = trans(batch_X, batch_Y)\n",
    "        \n",
    "#         print([tostr(y_) for y_ in y_pred])\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accum_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += batch_size * (MAX_LENGTH + 1) # For each \"<foo>\" predict and count \"foo>\" but MAX_LENGTH doesn't include <...>\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_training_accur = trans.score(X_train, Y_train)\n",
    "    epoch_test_accur = trans.score(X_test, Y_test)\n",
    "\n",
    "    epoch_training_accum_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} TRAIN loss {epoch_training_loss:7.4f} char accur {epoch_training_accum_accur:.4f} phrase accur {epoch_training_accur:.4f}    TEST accur {epoch_test_accur:.3f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comme c'est mignon : <how cute>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<look out>'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SINGLE RECORD\n",
    "print(tostr(X_test[2]), \":\", tostr(Y_test[2]))\n",
    "y_pred = trans.predict(X_test[2], Y_test[2])\n",
    "tostr(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i beg you> == <forget it>\n",
      "<got it> == <i got it>\n",
      "<look out> == <how cute>\n",
      "<sit here> == <come here>\n",
      "<use this> == <use this>\n",
      "<it riu0y> == <shut up>\n",
      "<marry me> == <call me>\n",
      "<we kome ome> == <we'll go>\n",
      "<cak orrrr<orrr<orrr == <grab him>\n",
      "<be nice> == <be nice>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# TEST ALL TEST RECORDS\n",
    "y_pred = trans.predict(X_test, Y_test)\n",
    "total_correct = 0\n",
    "for i,y_ in enumerate(y_pred[0:10]):\n",
    "    total_correct += tostr(Y_test[i])==tostr(y_)\n",
    "    print(tostr(y_), \"==\", tostr(Y_test[i]))\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501432664756447"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(X,Y,verbose=(0,1,2)):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = trans.predict(x)\n",
    "            y_pred = y_pred[0] # only one record for now\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose>0:\n",
    "                if verbose>1 or d>0:\n",
    "                    print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                    print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d/float(len(X)), total_correct/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training n=349 average Levenshtein score     2.99, perfect accuracy     0.50\n"
     ]
    }
   ],
   "source": [
    "avg_d, accur = check(X_train, Y_train, verbose=0)\n",
    "print(f\"Training n={len(X_train)} average Levenshtein score {avg_d:8.2f}, perfect accuracy {accur:8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<oublie   : <forget it>\n",
      "                     : <i beg you>          Levenshtein 8 out of 20\n",
      "<<<<<<j'ai compris   : <i got it>\n",
      "                     : <got it>             Levenshtein 2 out of 20\n",
      "comme c'est mignon   : <how cute>\n",
      "                     : <look out>           Levenshtein 5 out of 20\n",
      "<<<<<<<<<viens ici   : <come here>\n",
      "                     : <sit here>           Levenshtein 4 out of 20\n",
      "<<<<<<<<<<la ferme   : <shut up>\n",
      "                     : <it riu0y>           Levenshtein 7 out of 20\n",
      "<<<<<<<appelle-moi   : <call me>\n",
      "                     : <marry me>           Levenshtein 4 out of 20\n",
      "<<<<<<<<nous irons   : <we'll go>\n",
      "                     : <we kome ome>        Levenshtein 8 out of 20\n",
      "<<<<<<<<attrape-le   : <grab him>\n",
      "                     : <cak orrrr<orrr<orrr Levenshtein 18 out of 20\n",
      "<<<<<<<<<gardez-le   : <keep it>\n",
      "                     : <forget it>          Levenshtein 5 out of 20\n",
      "<<<<<c'est nouveau   : <it's new>\n",
      "                     : <i  inr>             Levenshtein 6 out of 20\n",
      "<<<<<<<<<on essaye   : <we try>\n",
      "                     : <he trie>            Levenshtein 3 out of 20\n",
      "suis-je en retard    : <am i late>\n",
      "                     : <i  it>              Levenshtein 6 out of 20\n",
      "<<<<<<<<j'adore ça   : <i love it>\n",
      "                     : <grab this>          Levenshtein 8 out of 20\n",
      "<<<<<<<calmez-vous   : <cool down>\n",
      "                     : <hus>                Levenshtein 9 out of 20\n",
      "<<<<<soyez gentils   : <be nice>\n",
      "                     : <lme over>           Levenshtein 6 out of 20\n",
      "<<<<<<<<<<garde-le   : <keep it>\n",
      "                     : <calm>               Levenshtein 7 out of 20\n",
      "<<<<<je téléphonai   : <i phoned>\n",
      "                     : <i''b>               Levenshtein 7 out of 20\n",
      "<<<<<je l'ai perdu   : <i lost it>\n",
      "                     : <i lost>             Levenshtein 3 out of 20\n",
      "<<je me suis amusé   : <i had fun>\n",
      "                     : <i  awe wonnrsee won Levenshtein 14 out of 20\n",
      "<<<<<<beau travail   : <good job>\n",
      "                     : <i  nienr>           Levenshtein 8 out of 20\n",
      "<<<<à tes souhaits   : <bless you>\n",
      "                     : <we lost>            Levenshtein 7 out of 20\n",
      "<<<<<<<<<<il court   : <he runs>\n",
      "                     : <she runs>           Levenshtein 1 out of 20\n",
      "<<<<<<<<<<allons-y   : <let's go>\n",
      "                     : <x>                  Levenshtein 8 out of 20\n",
      "<<<<viens chez moi   : <come over>\n",
      "                     : <he'b me>            Levenshtein 7 out of 20\n",
      "<<<<<<<<<touche ça   : <feel this>\n",
      "                     : <grab this>          Levenshtein 4 out of 20\n",
      "<<<<venez chez moi   : <come over>\n",
      "                     : <he'b me>            Levenshtein 7 out of 20\n",
      "<<<<soyez gentille   : <be nice>\n",
      "                     : <hurry up>           Levenshtein 8 out of 20\n",
      "<<<<<<<<<<<va t'en   : <go away>\n",
      "                     : <tôirrrânn;xjz>      Levenshtein 13 out of 20\n",
      "<<<<<<<<<<<oubliez   : <forget it>\n",
      "                     : <ho in>              Levenshtein 6 out of 20\n",
      "<<<<<<<<<descendez   : <get down>\n",
      "                     : <home>               Levenshtein 7 out of 20\n",
      "<<<<<<<<<<<revenez   : <come back>\n",
      "                     : <come over>          Levenshtein 4 out of 20\n",
      "<<<<<<<<<<ferme-la   : <shut up>\n",
      "                     : <felh5o;henúcdu eate Levenshtein 17 out of 20\n",
      "<<<<<<<<<<<<<monte   : <hop in>\n",
      "                     : <i am lwalm>         Levenshtein 9 out of 20\n",
      "<<parlez plus fort   : <speak up>\n",
      "                     : <she'1 rtpen>        Levenshtein 7 out of 20\n",
      "<<<<<<asseyez-vous   : <be seated>\n",
      "                     : <hus>                Levenshtein 8 out of 20\n",
      "<<<<<qui est mort    : <who died>\n",
      "                     : <d'4>                Levenshtein 7 out of 20\n",
      "<<<<<allez-vous en   : <go away>\n",
      "                     : <i'm fin>            Levenshtein 7 out of 20\n",
      "<<<<<<<<<j'essayai   : <i tried>\n",
      "                     : <i'll tell>          Levenshtein 7 out of 20\n",
      "<<<<<<<avertis tom   : <warn tom>\n",
      "                     : <stop tom>           Levenshtein 4 out of 20\n",
      "<<hors de question   : <no way>\n",
      "                     : <o'woœ>              Levenshtein 4 out of 20\n",
      "<<<<<<<<<<aide-moi   : <help me>\n",
      "                     : <marry me>           Levenshtein 5 out of 20\n",
      "<<<<<<<<<<<<<<pars   : <go away>\n",
      "                     : <i cdr>              Levenshtein 6 out of 20\n",
      "<<soyez équitables   : <be fair>\n",
      "                     : <be nidl>            Levenshtein 4 out of 20\n",
      "<<<<ne demande pas   : <don't ask>\n",
      "                     : <don't die>          Levenshtein 3 out of 20\n",
      "<<<<<<<<<tenez bon   : <hang on>\n",
      "                     : <har>                Levenshtein 5 out of 20\n",
      "<<je me suis marré   : <i had fun>\n",
      "                     : <i'm  au >           Levenshtein 6 out of 20\n",
      "<<<<<suis-je gros    : <am i fat>\n",
      "                     : <got it>             Levenshtein 6 out of 20\n",
      "<<<<<cessez le feu   : <hold fire>\n",
      "                     : <aim fire>           Levenshtein 4 out of 20\n",
      "<<<<<<<<<<<<à plus   : <see you>\n",
      "                     : <le>                 Levenshtein 6 out of 20\n",
      "<<<<<<<<<<<<génial   : <terrific>\n",
      "                     : <ho  niu  niu  niu   Levenshtein 17 out of 20\n",
      "<<<<<<je suis repu   : <i'm full>\n",
      "                     : <gn44:>              Levenshtein 8 out of 20\n",
      "<<<<<<<<<sentez ça   : <feel this>\n",
      "                     : <hold this>          Levenshtein 4 out of 20\n",
      "<<<<<<<<<<lève-toi   : <get up>\n",
      "                     : <get read>           Levenshtein 4 out of 20\n",
      "<<<<<<<<<prends-le   : <take it>\n",
      "                     : <calm>               Levenshtein 6 out of 20\n",
      "<<<<<<<<pas touche   : <hands off>\n",
      "                     : <i'mâgp>             Levenshtein 9 out of 20\n",
      "<<<<<<je m'en sers   : <i use it>\n",
      "                     : <wacdr>              Levenshtein 8 out of 20\n",
      "<<<<<<préviens tom   : <warn tom>\n",
      "                     : <stop tom>           Levenshtein 4 out of 20\n",
      "<<<<<<<essaie ceci   : <try this>\n",
      "                     : <use this>           Levenshtein 3 out of 20\n",
      "<<je suis rassasié   : <i'm full>\n",
      "                     : <i'egret>            Levenshtein 6 out of 20\n",
      "<<<<<<<<<<tiens ça   : <hold this>\n",
      "                     : <grab this>          Levenshtein 4 out of 20\n",
      "<<<<<<<qui est-il    : <who's he>\n",
      "                     : <how n>              Levenshtein 5 out of 20\n",
      "<<<<elle est venue   : <she came>\n",
      "                     : <i b's lwash you>    Levenshtein 13 out of 20\n",
      "<<<<<<<<<<<courage   : <cheer up>\n",
      "                     : <i niiiiiiihdll>     Levenshtein 14 out of 20\n",
      "<<<<je vous ai vus   : <i saw you>\n",
      "                     : <help it>            Levenshtein 8 out of 20\n",
      "<<je suis mouillée   : <i'm wet>\n",
      "                     : <i hbe3>             Levenshtein 5 out of 20\n",
      "<<<<<<<<<<<<au feu   : <fire>\n",
      "                     : <aim fire>           Levenshtein 4 out of 20\n",
      "<<<<<<<<<<<<avance   : <drive on>\n",
      "                     : <good luck>          Levenshtein 9 out of 20\n",
      "<<pour quoi faire    : <what for>\n",
      "                     : <i hoc>              Levenshtein 6 out of 20\n",
      "<<<<<<<<<<<<<<stop   : <stop>\n",
      "                     : < nuwimiggg>         Levenshtein 10 out of 20\n",
      "je suis paresseuse   : <i am lazy>\n",
      "                     : <i refuse>           Levenshtein 7 out of 20\n",
      "<<<<<<<appelez tom   : <call tom>\n",
      "                     : <stop tom>           Levenshtein 4 out of 20\n",
      "<<<<<<<j'ai 19 ans   : <i'm 19>\n",
      "                     : <gp>                 Levenshtein 6 out of 20\n",
      "<<<<<<<détends-toi   : <cool off>\n",
      "                     : <get out>            Levenshtein 6 out of 20\n",
      "<<<<<<<<je l'ai vu   : <i saw him>\n",
      "                     : <i saw you>          Levenshtein 3 out of 20\n",
      "<<<<<<<<je paierai   : <i'll pay>\n",
      "                     : <i'll try>           Levenshtein 2 out of 20\n",
      "<<<<<<<<touchez ça   : <feel this>\n",
      "                     : <hold this>          Levenshtein 4 out of 20\n",
      "<<<<<<halte au feu   : <hold fire>\n",
      "                     : <aim fire>           Levenshtein 4 out of 20\n",
      "<trouvez un boulot   : <get a job>\n",
      "                     : <good job>           Levenshtein 4 out of 20\n",
      "<<<c'est la sienne   : <it's his>\n",
      "                     : <i twtack>           Levenshtein 7 out of 20\n",
      "<<<<<<<écrivez-moi   : <write me>\n",
      "                     : <marry me>           Levenshtein 5 out of 20\n",
      "Testing n=88 average Levenshtein score     5.95, perfect accuracy     0.09\n"
     ]
    }
   ],
   "source": [
    "avg_d, accur = check(X_test, Y_test, verbose=1)\n",
    "print(f\"Testing n={len(X_test)} average Levenshtein score {avg_d:8.2f}, perfect accuracy {accur:8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
