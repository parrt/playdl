{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via LSTM\n",
    "\n",
    "Repeat previous RNN exercise but with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with fake LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7563, -1.3696,  0.8025, -0.2179,  0.4296,  0.5692],\n",
       "        [ 0.3080, -0.3438,  0.7850, -0.5541,  1.2419,  0.4789],\n",
       "        [-0.6685, -0.7192, -0.3011, -0.2866, -0.2973, -0.4047],\n",
       "        [-0.1385,  0.0389,  0.1752, -2.0938,  0.0946, -1.3086]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = 6\n",
    "hidden_size = 3\n",
    "n = 4\n",
    "rnn = nn.LSTM(input_size=input_features, hidden_size=hidden_size, num_layers=1)\n",
    "inputs = [torch.randn(1, input_features) for _ in range(n)] # make n vectors\n",
    "inputs = torch.cat(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7563, -1.3696,  0.8025, -0.2179,  0.4296,  0.5692]],\n",
       "\n",
       "        [[ 0.3080, -0.3438,  0.7850, -0.5541,  1.2419,  0.4789]],\n",
       "\n",
       "        [[-0.6685, -0.7192, -0.3011, -0.2866, -0.2973, -0.4047]],\n",
       "\n",
       "        [[-0.1385,  0.0389,  0.1752, -2.0938,  0.0946, -1.3086]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.reshape(len(inputs), 1, input_features)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(1, 1, hidden_size)\n",
    "c0 = torch.zeros(1, 1, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0173, -0.4704, -0.0694]],\n",
       "\n",
       "        [[ 0.0161, -0.6711, -0.0637]],\n",
       "\n",
       "        [[ 0.0702, -0.4553,  0.0381]],\n",
       "\n",
       "        [[ 0.0327, -0.6640,  0.0249]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, hc = rnn(inputs, (h0,c0))\n",
    "# output is shape (n, max sequence length, hidden_size)\n",
    "print(o.shape)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0327, -0.6640,  0.0249]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0813, -1.0328,  0.0695]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8341</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8355</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 14,  4,  0, 10, 10,  5, 14,  0,  4], dtype=int8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14, 14, 14,  0, 14], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous shape is now wrong for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10686, 29, 19])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape should be (num records, max name len, input features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 19, 29])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset=10_000\n",
    "X_train_onehot, y_train = X_train_onehot[:subset], torch.tensor(y_train[:subset].values).long()\n",
    "X_valid_onehot, y_valid = X_valid_onehot[:subset], torch.tensor(y_valid[:subset]).long()\n",
    "X_train_onehot = X_train_onehot.reshape(len(X_train_onehot), max_len, len(V))\n",
    "X_valid_onehot = X_valid_onehot.reshape(len(X_valid_onehot), max_len, len(V))\n",
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameLSTM(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, output_size):\n",
    "        super(LastNameLSTM, self).__init__()\n",
    "#         print(\"Model: \",input_features, hidden_size, output_size)\n",
    "        self.input_features = input_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.lstm = nn.LSTM(input_size=input_features,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        max_len = X.shape[1]\n",
    "        # LSTMs need hidden and state vectors, one per input symbol\n",
    "        # also this resets h, c for each batch, not sure that is good\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        h, c = h0, c0\n",
    "        \n",
    "        # output is shape (batch size, max_len, hidden_size)\n",
    "        o, (h,c) = self.lstm(X, (h,c))\n",
    "#         print(h.shape, c.shape) # [1, 19, 50]   [1, 19, 50]\n",
    "#         print(\"lstm o\", o.shape)\n",
    "        # o has ALL outputs, for each step as it works through chars of name.\n",
    "        # We only need the last output, which we run into final layer\n",
    "        # for classification\n",
    "        o = o[:,-1,:]\n",
    "#         print(\"last output\", o.shape)\n",
    "        o = self.V(o)\n",
    "        o = self.softmax(o)\n",
    "#         print(\"final layer\", o.shape)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "            epochs=350,\n",
    "            test_size=0.20,\n",
    "            learning_rate = 0.002,\n",
    "            batch_size=32,\n",
    "            weight_decay=1.e-4,\n",
    "            loss_fn=F.cross_entropy,\n",
    "            metric=accuracy_score,\n",
    "            print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y_prob\", y_prob.shape)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "#             print(\"y_prob\", y_prob.shape)\n",
    "#             y_prob = F.softmax(y_prob, dim=1)\n",
    "#             print(\"y_prob\", y_prob)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "#             print(\"y_pred\", y_pred)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "#             y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.8364,  1.8681   function 0.471, 0.457\n",
      "Epoch   4 loss  1.4803,  1.5285   function 0.547, 0.534\n",
      "Epoch   8 loss  1.3094,  1.3676   function 0.632, 0.612\n",
      "Epoch  12 loss  1.2019,  1.2867   function 0.666, 0.635\n",
      "Epoch  16 loss  1.1649,  1.2580   function 0.674, 0.642\n",
      "Epoch  20 loss  1.1239,  1.2348   function 0.683, 0.651\n",
      "Epoch  24 loss  1.0480,  1.1652   function 0.697, 0.667\n",
      "Epoch  28 loss  1.0299,  1.1580   function 0.698, 0.668\n",
      "Epoch  32 loss  0.9970,  1.1302   function 0.707, 0.667\n",
      "Epoch  36 loss  0.9451,  1.1095   function 0.719, 0.679\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameLSTM(input_features=len(V),\n",
    "                   hidden_size=50,\n",
    "                   output_size=len(y_cats))\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "# X input shape (max name len, num records, input features)\n",
    "train = TensorDataset(X_train_onehot.to(device), y_train.to(device))\n",
    "valid = TensorDataset(X_valid_onehot.to(device), y_valid.to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                        loss_fn=torch.nn.NLLLoss(),\n",
    "#                         loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=40,\n",
    "                        learning_rate=0.003,\n",
    "                        weight_decay=0.001,\n",
    "                        batch_size=64,  \n",
    "                        print_every=4)\n",
    "\n",
    "plot_history(history, yrange=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
